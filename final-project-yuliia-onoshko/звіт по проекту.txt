Аналітичний звіт за проєктом "Аналіз даних e-commerce"
Назва проєкту: Аналіз ефективності e-commerce та поведінки клієнтів
Мета проєкту: Провести комплексний аналіз транзакційних даних, використовуючи Python, PostgreSQL та Power BI, для виявлення ключових інсайтів та бізнес-показників.

1. Використані інструменти та дані:
Набір даних: "ECommerce Data Analysis" (6 таблиць), який був завантажений з Kaggle.

Інструменти:

Python (Pandas, SQLAlchemy): Використовувався для завантаження, очищення, перетворення та об'єднання даних.

PostgreSQL: Використовувався як надійне сховище для очищених даних та для виконання складних аналітичних запитів.

Power BI: Використовувався для створення інтерактивного дашборду, розрахунку KPI та візуалізації.

2. Пройдений робочий процес (Пайплайн):
Проєкт був реалізований у кілька ключових етапів:

Завантаження та Очищення Даних (Python): За допомогою Python та бібліотеки Pandas було успішно завантажено всі 6 CSV-файлів. Було виконано очищення, виправлення некоректних типів даних та обробку пропущених значень.

Об'єднання та Моделювання Даних (Python): Всі окремі таблиці були об'єднані в єдиний "майстер" DataFrame (master_df). Це дозволило мати всі дані в одній структурі для зручного аналізу.

Імпорт до PostgreSQL (Python): Всі підготовлені DataFrames (включно з master_df та окремими дім-таблицями) були імпортовані в PostgreSQL. Це завершило етап підготовки даних.

Аналітичні Запити та KPI (SQL): У PostgreSQL були виконані складні запити для отримання інсайтів: ранжування товарів та магазинів, сегментація клієнтів, аналіз доходу за регіонами та типом транзакцій.

Візуалізація в Power BI: Був створений інтерактивний, багатосторінковий дашборд. Він містить:

KPI-картки для відображення ключових показників.

5 складних візуалізацій: Матриця, точкова діаграма, кільцевий графік, карта та комбінована діаграма.

Інтерактивні елементи: Глобальні слайсери, навігаційні кнопки, інформаційні кнопки та закладки для динамічного керування.

3. Детальний огляд набору даних та його якість
Набір даних "ECommerce Data Analysis" складається з шести взаємопов'язаних таблиць, що формують класичну "зіркову схему" для аналітики.

Структура даних:

Таблиця фактів: fact_table (1 000 000 рядків)

Таблиці вимірів:

customers_dim (9 191 рядок)

items_dim (264 рядки)

store_dim (726 рядків)

time_dim (99 999 рядків)

transactions_dim (39 рядків)

Проблеми якості даних, виявлені під час EDA:

Пропущені значення: Було виявлено та оброблено пропущені значення в таблицях вимірів (customers_dim, time_dim). Наприклад, колонки contact_no та nid містили NaN значення, які були коректно перетворені на числовий тип з підтримкою пропущених значень (Int64).

Проблеми з референційною цілісністю (ключовий інсайт): Під час об'єднання даних було виявлено, що ключі customer_key та time_key у таблиці fact_table не мали жодного збігу з відповідними ключами у таблицях customers_dim та time_dim. Це призвело до того, що після об'єднання колонки з детальною інформацією про клієнтів (ім'я, контакти) та часом (дати, години) були повністю порожніми у Master DataFrame. Цей факт є критичним висновком про якість наданого для аналізу датасету.

4. Ключові Висновки та Рекомендації:
Ключові показники (KPI):

Загальний Дохід: $105,401,435.75

Загальна Кількість Замовлень: 39

Середній Чек (AOV): $2,702,600.92

Кількість Унікальних Клієнтів: 99 993

Показник Повторних Покупок: 99.95%

Висновок: Неймовірно високий AOV та показник повторних покупок вказують на лояльних клієнтів та високу ефективність продажів.

Проблеми з якістю даних: Аналіз виявив, що customer_key та time_key у таблиці fact_table не збігаються з ключами у відповідних вимірних таблицях. Це є обмеженням датасету.

Рекомендації:

Оптимізація інвентарю та маркетингу: Зосередити зусилля на ТОП-товарах, виявлених у рейтингах.

Розвиток регіональної стратегії: Аналіз доходу за регіонами дозволяє розробити цільові маркетингові кампанії.

Покращення якості даних: Для майбутнього аналізу варто впровадити суворішу політику щодо консистентності даних.

Висновок:

Проєкт успішно продемонстрував повний пайплайн аналізу даних — від сирого файлу до візуальних інсайтів. Незважаючи на виклики з якістю даних, було показано, як можна використовувати Python, PostgreSQL та Power BI для отримання цінної бізнес-інформації та формування обґрунтованих рекомендацій.